{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8dDgLD-7Hal"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import moviepy\n",
    "import librosa\n",
    "import glob\n",
    "import moviepy.editor as mp\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "import os\n",
    "from os import walk, listdir\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, BertForTokenClassification, BertForSequenceClassification,BertPreTrainedModel, BertModel, BertTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from scipy.io.wavfile import read\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5ne-6O88KdV"
   },
   "source": [
    "EXTRACTING TEXT FEATURES FROM TRANSCRIPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_DIR = '/path/to/folder/containing/transcriptions'\n",
    "TAREGT_DIR = '/path/to/folder/for/storing/features'\n",
    "CATEGORY = \"Explicit Hate Videos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allEmbedding ={}\n",
    "combined_df = pd.read_csv(f'{VIDEO_DIR}/transcriptions_{CATEGORY}.csv')\n",
    "df = pd.read_excel(f'{VIDEO_DIR}/{CATEGORY}.xlsx')\n",
    "cnt = 1\n",
    "\n",
    "for filename in (df['Video_ID']):\n",
    "  try:\n",
    "    file = filename + '.wav'\n",
    "    #print(file)\n",
    "    i = np.where(combined_df == file)[0][0]\n",
    "    inputs = tokenizer(combined_df['Transcription'][i], return_tensors=\"pt\", truncation = True, max_length=512, padding='max_length', add_special_tokens=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        last_hidden_states = outputs.last_hidden_state\n",
    "        allEmbedding[i]= last_hidden_states.detach().numpy()\n",
    "    del(outputs)\n",
    "    print(cnt)\n",
    "    cnt = cnt+1\n",
    "  except:\n",
    "    print(f\"Error processing {file}\")\n",
    "    allEmbedding[i] = np.zeros((1,512,768), dtype=float)\n",
    "    cnt = cnt+1\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array(list(allEmbedding.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = arr1.reshape((500, 512, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{TARGET_DIR}/{CATEGORY}2DBERTembedding.npy\",arr2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
