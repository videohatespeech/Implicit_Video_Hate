{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8dDgLD-7Hal"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import moviepy\n",
    "import librosa\n",
    "import glob\n",
    "import moviepy.editor as mp\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "import os\n",
    "from os import walk, listdir\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, BertForTokenClassification, BertForSequenceClassification,BertPreTrainedModel, BertModel, BertTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from scipy.io.wavfile import read\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACTING AUDIO FEATURES FROM AUDIO FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_mfcc(path):\n",
    "    audio, sr=librosa.load(path)\n",
    "    mfccs=librosa.feature.mfcc(audio, sr, n_mfcc=40)\n",
    "    return np.mean(mfccs.T, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME ='/path/to/folder/containing/audio files'\n",
    "CATEGORY = 'Explicit Hate Videos' #change to Implicit Hate Videos, Non Hate Videos as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allAudioFeatures = {}\n",
    "failedList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    #load the file (audio)\n",
    "    audio, sample_rate = librosa.load(file, res_type='kaiser_fast')\n",
    "    #we extract mfcc\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    #in order to find out scaled feature we do mean of transpose of value\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "df = pd.read_excel(f'/{FOLDER_NAME}/{CATEGORY}.xlsx') # Excel containing all the video names and IDs\n",
    "for filename in (df['Video_ID']+'.wav'):\n",
    "    try:\n",
    "        aud = features_extractor(FOLDER_NAME + filename)\n",
    "        allAudioFeatures[i]=aud\n",
    "    except:\n",
    "        print(\"Error\", i)\n",
    "        failedList.append(i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in failedList:\n",
    "    allAudioFeatures[i] = np.zeros(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_EH_MFCC = np.array(list(allAudioFeatures.values()))\n",
    "arr_EH_MFCC.shape\n",
    "np.save(f\"/path/to/folder/for/storing/features/{CATEGORY}_mfcc.npy\",arr_EH_MFCC)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
