{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8dDgLD-7Hal"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import moviepy\n",
    "import librosa\n",
    "import glob\n",
    "import moviepy.editor as mp\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "import matplotlib\n",
    "import tqdm\n",
    "import PIL\n",
    "import cv2 as cv\n",
    "import os\n",
    "from os import walk, listdir\n",
    "import shutil\n",
    "import subprocess\n",
    "import shlex\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from transformers import AutoTokenizer, BertForTokenClassification, BertForSequenceClassification,BertPreTrainedModel, BertModel, BertTokenizer, AutoModel\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn.functional as F\n",
    "from scipy.io.wavfile import read\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import ViTFeatureExtractor, ViTModel\n",
    "import requests\n",
    "from sys import stderr, stdout\n",
    "from torchvggish import vggish, vggish_input\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5INscsyiTMWr"
   },
   "source": [
    "EXTRACTING AUDIO FROM VIDEOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aO92SSEQfP8U"
   },
   "outputs": [],
   "source": [
    "VIDEO_DIR = '/path/to/folder/containing/videos/'\n",
    "OUTPUT_DIR = '/path/to/folder/for/storing/audio files'\n",
    "\n",
    "CATEGORY = \"Explicit Hate Videos\" #change it to Implicit Hate Videos, Non Hate Videos as required\n",
    "\n",
    "BW = 160\n",
    "OC = 1\n",
    "OF = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excel file containing the name and ids of videos\n",
    "df1 = pd.read_excel(f\"{VIDEO_DIR}/{CATEGORY}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_audio_stream(video_path):\n",
    "    \"\"\"Check if the video has an audio stream.\"\"\"\n",
    "    command = f\"ffmpeg -i {shlex.quote(video_path)}\"\n",
    "    result = subprocess.run(command, shell=True, stderr=subprocess.PIPE, text=True)\n",
    "    return \"Audio:\" in result.stderr\n",
    "\n",
    "def vToA():\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    cnt = 0\n",
    "\n",
    "    for video_id in df1[\"Video_ID\"]:\n",
    "        video = video_id + '.mp4'\n",
    "        video_path = os.path.join(VIDEO_DIR, video)\n",
    "        output_audio_path = os.path.join(OUTPUT_DIR, video_id + '.wav')\n",
    "\n",
    "        print(f\"Processing: {video_path}\")\n",
    "        \n",
    "        if not os.path.isfile(video_path):\n",
    "            print(f\"Video file not found: {video_path}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        if not has_audio_stream(video_path):\n",
    "            print(f\"No audio stream in {video}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        with open(os.devnull, \"w\") as ffmpeg_log:\n",
    "            try:\n",
    "                command = (\n",
    "                    f\"ffmpeg -i {shlex.quote(video_path)} -ab {BW}k -ac {OC} \"\n",
    "                    f\"-ar {OF} -vn {shlex.quote(output_audio_path)}\"\n",
    "                )\n",
    "                print(f\"Executing command: {command}\")\n",
    "                ret = subprocess.call(command, shell=True, stdout=ffmpeg_log, stderr=ffmpeg_log)\n",
    "\n",
    "                if ret != 0:\n",
    "                    print(f\"Error processing {video}. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                cnt += 1\n",
    "                print(f\"Processed {cnt}: {video}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred with {video}: {e}\")\n",
    "\n",
    "    print(f\"Conversion complete. Successful conversions: {cnt}\")\n",
    "\n",
    "vToA()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
